# ConfiguraciÃ³n para Vercel

Esta guÃ­a explica cÃ³mo configurar el proyecto para el despliegue en Vercel, especialmente la integraciÃ³n con OpenAI.

## ğŸš€ Variables de Entorno en Vercel

### ConfiguraciÃ³n en el Dashboard de Vercel

1. Ve a tu proyecto en el [Dashboard de Vercel](https://vercel.com/dashboard)
2. Navega a **Settings** â†’ **Environment Variables**
3. AÃ±ade la siguiente variable:

```
OPENAI_API_KEY=sk-tu-api-key-aqui
```

**Importante:**
- âœ… La variable debe estar disponible para **Production**, **Preview** y **Development**
- âœ… No incluyas espacios antes o despuÃ©s del `=`
- âœ… La API key debe comenzar con `sk-`

### Obtener tu API Key de OpenAI

1. Ve a [OpenAI Platform](https://platform.openai.com/api-keys)
2. Inicia sesiÃ³n o crea una cuenta
3. Crea una nueva API key
4. Copia la key y pÃ©gala en Vercel

## âš™ï¸ ConfiguraciÃ³n del Proyecto

El proyecto ya estÃ¡ configurado para funcionar en Vercel:

- âœ… **Streaming**: Compatible con Vercel Serverless Functions
- âœ… **Runtime**: Node.js (configurado en el route handler)
- âœ… **Timeouts**: Configurado para 30 segundos (requiere plan Pro para respuestas largas)
- âœ… **Headers**: Optimizados para streaming en Vercel

## ğŸ“ Notas Importantes

### LÃ­mites de Tiempo en Vercel

- **Plan Hobby**: 10 segundos mÃ¡ximo por funciÃ³n
- **Plan Pro**: 60 segundos mÃ¡ximo por funciÃ³n
- **Plan Enterprise**: Hasta 300 segundos

El cÃ³digo estÃ¡ configurado con `maxDuration = 30` segundos, lo que requiere al menos el plan Pro. Si estÃ¡s en el plan Hobby, cambia a `maxDuration = 10` en `app/api/chat/route.ts`.

### Streaming

El streaming funciona correctamente en Vercel. Los chunks se envÃ­an en tiempo real sin problemas.

### Monitoreo

Puedes monitorear las llamadas a la API en:
- **Vercel Dashboard** â†’ **Functions** â†’ Ver logs y mÃ©tricas
- **OpenAI Dashboard** â†’ Ver uso y costos

## ğŸ”’ Seguridad

- âœ… La API key **nunca** se expone al cliente
- âœ… Solo se usa en cÃ³digo de servidor (route handlers)
- âœ… Los errores no exponen informaciÃ³n sensible

## ğŸ§ª Probar Localmente

Para probar localmente antes de desplegar:

1. Crea un archivo `.env.local` en la raÃ­z del proyecto:
```env
OPENAI_API_KEY=sk-tu-api-key-aqui
```

2. Ejecuta:
```bash
npm run dev
```

3. Prueba el chat en `http://localhost:3000`

## ğŸ› Troubleshooting

### Error: "OPENAI_API_KEY no estÃ¡ configurada"

- Verifica que la variable estÃ© configurada en Vercel
- AsegÃºrate de que estÃ© disponible para el entorno correcto (Production/Preview)
- Redespliega el proyecto despuÃ©s de aÃ±adir la variable

### Error: "Function timeout"

- Verifica tu plan de Vercel
- Ajusta `maxDuration` segÃºn tu plan
- Considera usar un modelo mÃ¡s rÃ¡pido (ya estÃ¡s usando `gpt-4o-mini`)

### Streaming no funciona

- Verifica que los headers estÃ©n correctos
- Revisa los logs en Vercel Dashboard
- AsegÃºrate de que el cliente estÃ© leyendo el stream correctamente

